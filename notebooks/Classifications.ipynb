{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, recall_score, f1_score, precision_score\n",
    "from joblib import dump, load\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import scipy.stats as stats\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking the classification Power of the synth data created from data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"../data/processed/sorted_train_data_mm.csv\")\n",
    "\n",
    "synthetic_data_paths = [\n",
    "    # Test Data\n",
    "    \"../data/processed/sorted_test_data_mm.csv\",\n",
    "    # Base Model\n",
    "    \"../data/interim/generated/Base/id1_repeat_data.csv\",\n",
    "    \"../data/interim/generated/Base/id1_repeat_sample.csv\",\n",
    "    # this is the experiment with the top values of the d-generation process\n",
    "    \"../data/interim/generated/D-Generation/3646_b_b0_1kl_0_0001_l_64_n512_data_no_batch.csv\",\n",
    "    \"../data/interim/generated/D-Generation/467_a_b0_1kl_0_0001_l_4_n512_data_no_batch.csv\",\n",
    "    \"../data/interim/generated/D-Generation/3646_b_b0_1kl_0_0001_l_64_n512_data_batch.csv\",\n",
    "    \"../data/interim/generated/D-Generation/1393_b_b0_1kl_0_0001_l_32_n512_data_no_batch.csv\",\n",
    "    \"../data/interim/generated/D-Generation/1393_b_b0_1kl_0_0001_l_32_n512_data_batch.csv\",\n",
    "    \"../data/interim/generated/D-Generation/966_a_b0_1kl_0_0001_l_16_n256_data_no_batch.csv\",\n",
    "    \"../data/interim/generated/D-Generation/2767_b_b0_1kl_0_0001_l_2_n256_128_data_no_batch.csv\",\n",
    "    # here are the values of the s-generation process only sampling\n",
    "    \"../data/interim/generated/S-Generation/1517_c_b1kl_1_l_2_n512_batch_sample_sample.csv\",\n",
    "    # back to cgan to compare\n",
    "    \"../data/interim/generated/CGANEPOCH2.csv\",\n",
    "    # Oversampling\n",
    "    \"../data/interim/generated/S-Generation/1517_c_b1kl_1_l_2_n512_oversample_02_sample.csv\",\n",
    "    \"../data/interim/generated/S-Generation/1517_c_b1kl_1_l_2_n512_oversample_01_sample.csv\",\n",
    "    \"../data/interim/generated/S-Generation/1517_c_b1kl_1_l_2_n512_oversample_005_sample.csv\",\n",
    "    \"../data/interim/generated/S-Generation/1517_c_b1kl_1_l_2_n512_oversample_001_sample.csv\",\n",
    "]\n",
    "\n",
    "file_names = [path.split(\"/\")[-1].split(\".\")[0] for path in synthetic_data_paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "synth_data_dict = {}\n",
    "\n",
    "for path, file_name in zip(synthetic_data_paths, file_names):\n",
    "    synth_data_dict[file_name] = {}\n",
    "    synth_data = pd.read_csv(path)\n",
    "    synth_data_dict[file_name][\"X\"] = synth_data.values[:, :-1]\n",
    "    synth_data_dict[file_name][\"y\"] = synth_data.values[:, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Random forest and Logistic Regression on original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load train_data\n",
    "# X = synth_data_dict[\"sorted_train_data_mm\"][\"X\"]\n",
    "# y = synth_data_dict[\"sorted_train_data_mm\"][\"y\"]\n",
    "\n",
    "# # Random Forest\n",
    "# random_forest = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)\n",
    "# random_forest.fit(X, y)\n",
    "# dump(random_forest, \"../models/Classifier/random_forest_model.joblib\")\n",
    "\n",
    "# # Logistic Regression\n",
    "# logistic_regression = LogisticRegression()\n",
    "# logistic_regression.fit(X, y)\n",
    "# dump(logistic_regression, \"../models/Classifier/logistic_regression.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest = load(\"../models/Classifier/random_forest_model.joblib\")\n",
    "logistic_regression = load(\"../models/Classifier/logistic_regression.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_performance_classification(model, X, y, name, *args):\n",
    "    # Predictions on training and testing data\n",
    "    y_pred = model.predict(X)\n",
    "    # Accuracy scores\n",
    "    accuracy = accuracy_score(y, y_pred)\n",
    "    # Recall scores\n",
    "    recall = recall_score(y, y_pred)\n",
    "    # Precision\n",
    "    precision = precision_score(y, y_pred)\n",
    "    # F1 scores\n",
    "    f1 = f1_score(y, y_pred)\n",
    "    # Confusion Matrix\n",
    "    conf_matrix = confusion_matrix(y, y_pred)\n",
    "\n",
    "    mean_diff_list = []\n",
    "    kl_div_list = []\n",
    "\n",
    "    for column1, column2 in zip(\n",
    "        np.transpose(synth_data_dict[\"sorted_test_data_mm\"][\"X\"]),\n",
    "        np.transpose(X)):\n",
    "\n",
    "        mean_diff_list.append(np.mean(column1) - np.mean(column2))\n",
    "\n",
    "        hist_test, _ = np.histogram(\n",
    "            column1, bins=40\n",
    "        )\n",
    "        hist_prob_test = hist_test / len(column1)\n",
    "\n",
    "        hist_synth, _ = np.histogram(\n",
    "            column2, bins=40\n",
    "        )\n",
    "        hist_prob_synth = hist_synth / len(column2)\n",
    "\n",
    "        kl_div = tf.keras.losses.kullback_leibler_divergence(hist_prob_test, hist_prob_synth)\n",
    "        kl_div_list.append(kl_div.numpy())\n",
    "\n",
    "    mean_class = sum(y)/len(y)  \n",
    "    mean_diff = np.sum(mean_diff_list) / len(mean_diff_list)\n",
    "    kl_div_value = np.sum(kl_div_list) / len(kl_div_list)\n",
    "\n",
    "    # Create new row\n",
    "    row =  [model, name, accuracy, recall, precision, f1, conf_matrix, mean_diff, mean_class, kl_div_value] #mean_f_value, p_value_low, p_value_up]\n",
    "\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_evaluation = pd.DataFrame(\n",
    "    columns=[\n",
    "        \"Model\",\n",
    "        \"Data Set\",\n",
    "        \"Accuracy\",\n",
    "        \"Recall\",\n",
    "        \"Precision\",\n",
    "        \"F1 Score\",\n",
    "        \"Confusion Matrix\",\n",
    "        \"mean_diff\",\n",
    "        \"mean_class\",\n",
    "        \"kl_div_value\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "for key in synth_data_dict:\n",
    "    X = synth_data_dict[key][\"X\"]\n",
    "    y = synth_data_dict[key][\"y\"]\n",
    "    evaluation_result = evaluate_model_performance_classification(random_forest, X, y, key)\n",
    "    df_evaluation.loc[len(df_evaluation)] = evaluation_result\n",
    "\n",
    "# for key in synth_data_dict:\n",
    "#     X = synth_data_dict[key][\"X\"]\n",
    "#     y = synth_data_dict[key][\"y\"]\n",
    "#     evaluation_result = evaluate_model_performance_classification(\n",
    "#         logistic_regression, X, y, key\n",
    "#     )\n",
    "#     df_evaluation.loc[len(df_evaluation)] = evaluation_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Data Set</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Confusion Matrix</th>\n",
       "      <th>mean_diff</th>\n",
       "      <th>mean_class</th>\n",
       "      <th>kl_div_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(DecisionTreeClassifier(max_depth=10, max_feat...</td>\n",
       "      <td>id1_repeat_sample</td>\n",
       "      <td>0.999912</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>[[56955, 1], [4, 2]]</td>\n",
       "      <td>0.003517</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>4.454869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(DecisionTreeClassifier(max_depth=10, max_feat...</td>\n",
       "      <td>1517_c_b1kl_1_l_2_n512_batch_sample_sample</td>\n",
       "      <td>0.999702</td>\n",
       "      <td>0.564103</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.721311</td>\n",
       "      <td>[[56923, 0], [17, 22]]</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000685</td>\n",
       "      <td>6.303054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>(DecisionTreeClassifier(max_depth=10, max_feat...</td>\n",
       "      <td>1517_c_b1kl_1_l_2_n512_oversample_01_sample</td>\n",
       "      <td>0.995260</td>\n",
       "      <td>0.811321</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.895833</td>\n",
       "      <td>[[55531, 0], [270, 1161]]</td>\n",
       "      <td>-0.000104</td>\n",
       "      <td>0.025122</td>\n",
       "      <td>2.666527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>(DecisionTreeClassifier(max_depth=10, max_feat...</td>\n",
       "      <td>1517_c_b1kl_1_l_2_n512_oversample_001_sample</td>\n",
       "      <td>0.999368</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.829384</td>\n",
       "      <td>0.906736</td>\n",
       "      <td>[[56751, 36], [0, 175]]</td>\n",
       "      <td>-0.000788</td>\n",
       "      <td>0.003072</td>\n",
       "      <td>4.228778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>(DecisionTreeClassifier(max_depth=10, max_feat...</td>\n",
       "      <td>1517_c_b1kl_1_l_2_n512_oversample_005_sample</td>\n",
       "      <td>0.998754</td>\n",
       "      <td>0.892922</td>\n",
       "      <td>0.976190</td>\n",
       "      <td>0.932701</td>\n",
       "      <td>[[56399, 12], [59, 492]]</td>\n",
       "      <td>0.000691</td>\n",
       "      <td>0.009673</td>\n",
       "      <td>2.602489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(DecisionTreeClassifier(max_depth=10, max_feat...</td>\n",
       "      <td>1517_c_b1kl_1_l_2_n512_oversample_02_sample</td>\n",
       "      <td>0.988712</td>\n",
       "      <td>0.930983</td>\n",
       "      <td>0.980502</td>\n",
       "      <td>0.955101</td>\n",
       "      <td>[[49480, 136], [507, 6839]]</td>\n",
       "      <td>0.004420</td>\n",
       "      <td>0.128963</td>\n",
       "      <td>4.239298</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Model  \\\n",
       "2   (DecisionTreeClassifier(max_depth=10, max_feat...   \n",
       "10  (DecisionTreeClassifier(max_depth=10, max_feat...   \n",
       "13  (DecisionTreeClassifier(max_depth=10, max_feat...   \n",
       "15  (DecisionTreeClassifier(max_depth=10, max_feat...   \n",
       "14  (DecisionTreeClassifier(max_depth=10, max_feat...   \n",
       "12  (DecisionTreeClassifier(max_depth=10, max_feat...   \n",
       "\n",
       "                                        Data Set  Accuracy    Recall  \\\n",
       "2                              id1_repeat_sample  0.999912  0.333333   \n",
       "10    1517_c_b1kl_1_l_2_n512_batch_sample_sample  0.999702  0.564103   \n",
       "13   1517_c_b1kl_1_l_2_n512_oversample_01_sample  0.995260  0.811321   \n",
       "15  1517_c_b1kl_1_l_2_n512_oversample_001_sample  0.999368  1.000000   \n",
       "14  1517_c_b1kl_1_l_2_n512_oversample_005_sample  0.998754  0.892922   \n",
       "12   1517_c_b1kl_1_l_2_n512_oversample_02_sample  0.988712  0.930983   \n",
       "\n",
       "    Precision  F1 Score             Confusion Matrix  mean_diff  mean_class  \\\n",
       "2    0.666667  0.444444         [[56955, 1], [4, 2]]   0.003517    0.000105   \n",
       "10   1.000000  0.721311       [[56923, 0], [17, 22]]   0.000050    0.000685   \n",
       "13   1.000000  0.895833    [[55531, 0], [270, 1161]]  -0.000104    0.025122   \n",
       "15   0.829384  0.906736      [[56751, 36], [0, 175]]  -0.000788    0.003072   \n",
       "14   0.976190  0.932701     [[56399, 12], [59, 492]]   0.000691    0.009673   \n",
       "12   0.980502  0.955101  [[49480, 136], [507, 6839]]   0.004420    0.128963   \n",
       "\n",
       "    kl_div_value  \n",
       "2       4.454869  \n",
       "10      6.303054  \n",
       "13      2.666527  \n",
       "15      4.228778  \n",
       "14      2.602489  \n",
       "12      4.239298  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_evaluation.query(\n",
    "    '`Data Set`.str.contains(\"sample\")'\n",
    ").sort_values(\"F1 Score\", ascending=True).sort_values(\"F1 Score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Data Set</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Confusion Matrix</th>\n",
       "      <th>mean_diff</th>\n",
       "      <th>mean_class</th>\n",
       "      <th>kl_div_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(DecisionTreeClassifier(max_depth=10, max_feat...</td>\n",
       "      <td>2767_b_b0_1kl_0_0001_l_2_n256_128_data_no_batch</td>\n",
       "      <td>0.999807</td>\n",
       "      <td>0.934783</td>\n",
       "      <td>0.945055</td>\n",
       "      <td>0.939891</td>\n",
       "      <td>[[56865, 5], [6, 86]]</td>\n",
       "      <td>0.000459</td>\n",
       "      <td>0.001615</td>\n",
       "      <td>6.421584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(DecisionTreeClassifier(max_depth=10, max_feat...</td>\n",
       "      <td>1393_b_b0_1kl_0_0001_l_32_n512_data_no_batch</td>\n",
       "      <td>0.999579</td>\n",
       "      <td>0.836957</td>\n",
       "      <td>0.895349</td>\n",
       "      <td>0.865169</td>\n",
       "      <td>[[56861, 9], [15, 77]]</td>\n",
       "      <td>-0.000084</td>\n",
       "      <td>0.001615</td>\n",
       "      <td>2.346215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(DecisionTreeClassifier(max_depth=10, max_feat...</td>\n",
       "      <td>sorted_test_data_mm</td>\n",
       "      <td>0.999544</td>\n",
       "      <td>0.771739</td>\n",
       "      <td>0.934211</td>\n",
       "      <td>0.845238</td>\n",
       "      <td>[[56865, 5], [21, 71]]</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001615</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(DecisionTreeClassifier(max_depth=10, max_feat...</td>\n",
       "      <td>467_a_b0_1kl_0_0001_l_4_n512_data_no_batch</td>\n",
       "      <td>0.999473</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.907895</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>[[56863, 7], [23, 69]]</td>\n",
       "      <td>0.001596</td>\n",
       "      <td>0.001615</td>\n",
       "      <td>4.857539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(DecisionTreeClassifier(max_depth=10, max_feat...</td>\n",
       "      <td>3646_b_b0_1kl_0_0001_l_64_n512_data_no_batch</td>\n",
       "      <td>0.999438</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>[[56862, 8], [24, 68]]</td>\n",
       "      <td>-0.000085</td>\n",
       "      <td>0.001615</td>\n",
       "      <td>2.322000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(DecisionTreeClassifier(max_depth=10, max_feat...</td>\n",
       "      <td>id1_repeat_data</td>\n",
       "      <td>0.999456</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.981818</td>\n",
       "      <td>0.776978</td>\n",
       "      <td>[[56877, 1], [30, 54]]</td>\n",
       "      <td>0.003515</td>\n",
       "      <td>0.001475</td>\n",
       "      <td>2.926744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(DecisionTreeClassifier(max_depth=10, max_feat...</td>\n",
       "      <td>966_a_b0_1kl_0_0001_l_16_n256_data_no_batch</td>\n",
       "      <td>0.999333</td>\n",
       "      <td>0.684783</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.768293</td>\n",
       "      <td>[[56861, 9], [29, 63]]</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.001615</td>\n",
       "      <td>2.427511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(DecisionTreeClassifier(max_depth=10, max_feat...</td>\n",
       "      <td>3646_b_b0_1kl_0_0001_l_64_n512_data_batch</td>\n",
       "      <td>0.999298</td>\n",
       "      <td>0.663043</td>\n",
       "      <td>0.871429</td>\n",
       "      <td>0.753086</td>\n",
       "      <td>[[56861, 9], [31, 61]]</td>\n",
       "      <td>0.000828</td>\n",
       "      <td>0.001615</td>\n",
       "      <td>2.322265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(DecisionTreeClassifier(max_depth=10, max_feat...</td>\n",
       "      <td>1393_b_b0_1kl_0_0001_l_32_n512_data_batch</td>\n",
       "      <td>0.999228</td>\n",
       "      <td>0.619565</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.721519</td>\n",
       "      <td>[[56861, 9], [35, 57]]</td>\n",
       "      <td>0.000790</td>\n",
       "      <td>0.001615</td>\n",
       "      <td>2.087815</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Model  \\\n",
       "9  (DecisionTreeClassifier(max_depth=10, max_feat...   \n",
       "6  (DecisionTreeClassifier(max_depth=10, max_feat...   \n",
       "0  (DecisionTreeClassifier(max_depth=10, max_feat...   \n",
       "4  (DecisionTreeClassifier(max_depth=10, max_feat...   \n",
       "3  (DecisionTreeClassifier(max_depth=10, max_feat...   \n",
       "1  (DecisionTreeClassifier(max_depth=10, max_feat...   \n",
       "8  (DecisionTreeClassifier(max_depth=10, max_feat...   \n",
       "5  (DecisionTreeClassifier(max_depth=10, max_feat...   \n",
       "7  (DecisionTreeClassifier(max_depth=10, max_feat...   \n",
       "\n",
       "                                          Data Set  Accuracy    Recall  \\\n",
       "9  2767_b_b0_1kl_0_0001_l_2_n256_128_data_no_batch  0.999807  0.934783   \n",
       "6     1393_b_b0_1kl_0_0001_l_32_n512_data_no_batch  0.999579  0.836957   \n",
       "0                              sorted_test_data_mm  0.999544  0.771739   \n",
       "4       467_a_b0_1kl_0_0001_l_4_n512_data_no_batch  0.999473  0.750000   \n",
       "3     3646_b_b0_1kl_0_0001_l_64_n512_data_no_batch  0.999438  0.739130   \n",
       "1                                  id1_repeat_data  0.999456  0.642857   \n",
       "8      966_a_b0_1kl_0_0001_l_16_n256_data_no_batch  0.999333  0.684783   \n",
       "5        3646_b_b0_1kl_0_0001_l_64_n512_data_batch  0.999298  0.663043   \n",
       "7        1393_b_b0_1kl_0_0001_l_32_n512_data_batch  0.999228  0.619565   \n",
       "\n",
       "   Precision  F1 Score        Confusion Matrix  mean_diff  mean_class  \\\n",
       "9   0.945055  0.939891   [[56865, 5], [6, 86]]   0.000459    0.001615   \n",
       "6   0.895349  0.865169  [[56861, 9], [15, 77]]  -0.000084    0.001615   \n",
       "0   0.934211  0.845238  [[56865, 5], [21, 71]]   0.000000    0.001615   \n",
       "4   0.907895  0.821429  [[56863, 7], [23, 69]]   0.001596    0.001615   \n",
       "3   0.894737  0.809524  [[56862, 8], [24, 68]]  -0.000085    0.001615   \n",
       "1   0.981818  0.776978  [[56877, 1], [30, 54]]   0.003515    0.001475   \n",
       "8   0.875000  0.768293  [[56861, 9], [29, 63]]   0.000076    0.001615   \n",
       "5   0.871429  0.753086  [[56861, 9], [31, 61]]   0.000828    0.001615   \n",
       "7   0.863636  0.721519  [[56861, 9], [35, 57]]   0.000790    0.001615   \n",
       "\n",
       "   kl_div_value  \n",
       "9      6.421584  \n",
       "6      2.346215  \n",
       "0      0.000000  \n",
       "4      4.857539  \n",
       "3      2.322000  \n",
       "1      2.926744  \n",
       "8      2.427511  \n",
       "5      2.322265  \n",
       "7      2.087815  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_evaluation.query(\"`Data Set`.str.contains('data')\").sort_values(\"F1 Score\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking the regression and correlation Power of the synth data created from data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creation of the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test_data dictionary\n",
    "test_data_dict = {}\n",
    "\n",
    "for key in synth_data_dict.keys():\n",
    "    if len(synth_data_dict[key][\"X\"]) == 56962:\n",
    "        X = synth_data_dict[key][\"X\"]\n",
    "        test_data_dict[key] = X\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "# Train Data Dictionary\n",
    "train_data_dict = {}\n",
    "\n",
    "for key in synth_data_dict:\n",
    "    if len(synth_data_dict[key][\"X\"]) == 199364:\n",
    "        train_data_dict[key] = synth_data_dict[key][\"X\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorted test data dictionary, because the data had an original ordering\n",
    "\n",
    "test_data_dict = {}\n",
    "sorted_test_data_dict = {}\n",
    "\n",
    "for key in synth_data_dict.keys():\n",
    "    # leaving out data, that has still or already has an ordering\n",
    "    if key == \"synthdata_from_data_test\" or key == \"sorted_test_data_mm\":\n",
    "        sorted_test_data_dict[key] = synth_data_dict[key][\"X\"]\n",
    "    elif (\n",
    "        len(synth_data_dict[key][\"X\"]) == 56962\n",
    "    ):\n",
    "        X = synth_data_dict[key][\"X\"]\n",
    "        sorted_indices = np.argsort(X[:, 0])\n",
    "        sorted_data = X[sorted_indices]\n",
    "        sorted_test_data_dict[key] = sorted_data\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Columnwise Correlations between orginal data and synth data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean correlation for key sorted_test_data_mm: 1.0\n",
      "Mean correlation for key id1_repeat_data: 0.03248867810548032\n",
      "Mean correlation for key id1_repeat_sample: 0.03275890536821562\n",
      "Mean correlation for key 3646_b_b0_1kl_0_0001_l_64_n512_data_no_batch: 0.08407186745142803\n",
      "Mean correlation for key 467_a_b0_1kl_0_0001_l_4_n512_data_no_batch: 0.10929746398109595\n",
      "Mean correlation for key 3646_b_b0_1kl_0_0001_l_64_n512_data_batch: 0.08544166940477699\n",
      "Mean correlation for key 1393_b_b0_1kl_0_0001_l_32_n512_data_no_batch: 0.08230100374766043\n",
      "Mean correlation for key 1393_b_b0_1kl_0_0001_l_32_n512_data_batch: 0.08482614286981514\n",
      "Mean correlation for key 966_a_b0_1kl_0_0001_l_16_n256_data_no_batch: 0.08454044661050411\n",
      "Mean correlation for key 2767_b_b0_1kl_0_0001_l_2_n256_128_data_no_batch: 0.1174815616324841\n",
      "Mean correlation for key 1517_c_b1kl_1_l_2_n512_batch_sample_sample: 0.01782774399852233\n",
      "Mean correlation for key CGANEPOCH2: 0.014172250112513425\n",
      "Mean correlation for key 1517_c_b1kl_1_l_2_n512_oversample_02_sample: 0.03294154413227777\n",
      "Mean correlation for key 1517_c_b1kl_1_l_2_n512_oversample_01_sample: 0.04983712052237523\n",
      "Mean correlation for key 1517_c_b1kl_1_l_2_n512_oversample_005_sample: 0.02492694838178332\n",
      "Mean correlation for key 1517_c_b1kl_1_l_2_n512_oversample_001_sample: 0.03455654378898024\n"
     ]
    }
   ],
   "source": [
    "# Calcualte the correlation for the sorted test data\n",
    "\n",
    "for key in list(sorted_test_data_dict.keys()):\n",
    "    corr_list = []\n",
    "    for i in range(0, 30):\n",
    "        corr = np.corrcoef(\n",
    "            sorted_test_data_dict[\"sorted_test_data_mm\"][:, i],\n",
    "            sorted_test_data_dict[key][:, i],\n",
    "        )[0, 1]\n",
    "        corr_list.append(corr)\n",
    "    mean_corr = np.mean(corr_list)\n",
    "    print(f\"Mean correlation for key {key}: {mean_corr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_regression(X, y):\n",
    "    model = LinearRegression()\n",
    "    # Predictions on training and testing data\n",
    "    fitted_regresion = model.fit(X, y)\n",
    "    y_pred = fitted_regresion.predict(X)\n",
    "    mse = mean_squared_error(y, y_pred)\n",
    "    r2 = r2_score(y, y_pred)\n",
    "\n",
    "    return mse, r2, fitted_regresion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_performance_regression(X, y, fitted_regression):\n",
    "    y_pred = fitted_regression.predict(X)\n",
    "    mse = mean_squared_error(y, y_pred)\n",
    "    r2 = r2_score(y, y_pred)\n",
    "    return mse, r2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the Regression for the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean mse of all columns is 0.0028647283347766517\n",
      " The mean r2 of all columns is 0.2368110425314998\n"
     ]
    }
   ],
   "source": [
    "regression_dict_test = {}\n",
    "\n",
    "mse_list = []\n",
    "r2_list = []\n",
    "\n",
    "for i in range(30):\n",
    "    X = np.delete(sorted_test_data_dict[\"sorted_test_data_mm\"], i, axis=1)\n",
    "    y = sorted_test_data_dict[\"sorted_test_data_mm\"][:, i]\n",
    "    mse, r2, fitted_regression = create_regression(X, y)\n",
    "\n",
    "    regression_dict_test[i] = {}\n",
    "    regression_dict_test[i][\"mse\"] = mse\n",
    "    regression_dict_test[i][\"r2\"] = r2\n",
    "    regression_dict_test[i][\"model\"] = fitted_regression\n",
    "\n",
    "    mse_list.append(mse)\n",
    "    r2_list.append(r2)\n",
    "\n",
    "print(f\"The mean mse of all columns is {sum(mse_list)/len(mse_list)}\")\n",
    "print(f\" The mean r2 of all columns is {sum(r2_list)/len(r2_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean mse value for all columns of table sorted_test_data_mm is 0.0028647283347766517\n",
      "The mean r2 value for all columns  of table sorted_test_data_mm is 0.2368110425314998 \n",
      "The correlation for mse of all columns of table sorted_test_data_mm is 1.0\n",
      "The correlation for r2 of all columns of table sorted_test_data_mm is 1.0\n",
      "The mean mse value for all columns of table id1_repeat_data is 0.0009142621626083672\n",
      "The mean r2 value for all columns  of table id1_repeat_data is -4.4836909648911485 \n",
      "The correlation for mse of all columns of table id1_repeat_data is 0.8575681002593363\n",
      "The correlation for r2 of all columns of table id1_repeat_data is -0.006144775574664058\n",
      "The mean mse value for all columns of table id1_repeat_sample is 0.0009052873958459876\n",
      "The mean r2 value for all columns  of table id1_repeat_sample is -4.4866841712154075 \n",
      "The correlation for mse of all columns of table id1_repeat_sample is 0.8635005192631333\n",
      "The correlation for r2 of all columns of table id1_repeat_sample is -0.00791626838599385\n",
      "The mean mse value for all columns of table 3646_b_b0_1kl_0_0001_l_64_n512_data_no_batch is 0.002776913558626695\n",
      "The mean r2 value for all columns  of table 3646_b_b0_1kl_0_0001_l_64_n512_data_no_batch is 0.20080124560777182 \n",
      "The correlation for mse of all columns of table 3646_b_b0_1kl_0_0001_l_64_n512_data_no_batch is 0.9998655039398905\n",
      "The correlation for r2 of all columns of table 3646_b_b0_1kl_0_0001_l_64_n512_data_no_batch is 0.9321355475586058\n",
      "The mean mse value for all columns of table 467_a_b0_1kl_0_0001_l_4_n512_data_no_batch is 0.0018976516225018881\n",
      "The mean r2 value for all columns  of table 467_a_b0_1kl_0_0001_l_4_n512_data_no_batch is 0.04056108369787248 \n",
      "The correlation for mse of all columns of table 467_a_b0_1kl_0_0001_l_4_n512_data_no_batch is 0.9944092528868433\n",
      "The correlation for r2 of all columns of table 467_a_b0_1kl_0_0001_l_4_n512_data_no_batch is 0.4601451530737946\n",
      "The mean mse value for all columns of table 3646_b_b0_1kl_0_0001_l_64_n512_data_batch is 0.0027415896233329716\n",
      "The mean r2 value for all columns  of table 3646_b_b0_1kl_0_0001_l_64_n512_data_batch is 0.1946755772484355 \n",
      "The correlation for mse of all columns of table 3646_b_b0_1kl_0_0001_l_64_n512_data_batch is 0.9996456114946298\n",
      "The correlation for r2 of all columns of table 3646_b_b0_1kl_0_0001_l_64_n512_data_batch is 0.9516842834778008\n",
      "The mean mse value for all columns of table 1393_b_b0_1kl_0_0001_l_32_n512_data_no_batch is 0.0028840106669608097\n",
      "The mean r2 value for all columns  of table 1393_b_b0_1kl_0_0001_l_32_n512_data_no_batch is 0.19262138899279255 \n",
      "The correlation for mse of all columns of table 1393_b_b0_1kl_0_0001_l_32_n512_data_no_batch is 0.9999112994312275\n",
      "The correlation for r2 of all columns of table 1393_b_b0_1kl_0_0001_l_32_n512_data_no_batch is 0.9166371113468558\n",
      "The mean mse value for all columns of table 1393_b_b0_1kl_0_0001_l_32_n512_data_batch is 0.0027154447897157668\n",
      "The mean r2 value for all columns  of table 1393_b_b0_1kl_0_0001_l_32_n512_data_batch is 0.2123229777228318 \n",
      "The correlation for mse of all columns of table 1393_b_b0_1kl_0_0001_l_32_n512_data_batch is 0.999799506687028\n",
      "The correlation for r2 of all columns of table 1393_b_b0_1kl_0_0001_l_32_n512_data_batch is 0.9532943245280995\n",
      "The mean mse value for all columns of table 966_a_b0_1kl_0_0001_l_16_n256_data_no_batch is 0.0025956050443100686\n",
      "The mean r2 value for all columns  of table 966_a_b0_1kl_0_0001_l_16_n256_data_no_batch is 0.2513877873004335 \n",
      "The correlation for mse of all columns of table 966_a_b0_1kl_0_0001_l_16_n256_data_no_batch is 0.9990588868667474\n",
      "The correlation for r2 of all columns of table 966_a_b0_1kl_0_0001_l_16_n256_data_no_batch is 0.9787229084446524\n",
      "The mean mse value for all columns of table 2767_b_b0_1kl_0_0001_l_2_n256_128_data_no_batch is 0.001276663984354645\n",
      "The mean r2 value for all columns  of table 2767_b_b0_1kl_0_0001_l_2_n256_128_data_no_batch is -0.47322950294860316 \n",
      "The correlation for mse of all columns of table 2767_b_b0_1kl_0_0001_l_2_n256_128_data_no_batch is 0.9905784837682093\n",
      "The correlation for r2 of all columns of table 2767_b_b0_1kl_0_0001_l_2_n256_128_data_no_batch is 0.08421932005754294\n",
      "The mean mse value for all columns of table 1517_c_b1kl_1_l_2_n512_batch_sample_sample is 3.566312882685247e-05\n",
      "The mean r2 value for all columns  of table 1517_c_b1kl_1_l_2_n512_batch_sample_sample is -3.6299279060266705 \n",
      "The correlation for mse of all columns of table 1517_c_b1kl_1_l_2_n512_batch_sample_sample is 0.8036733355220274\n",
      "The correlation for r2 of all columns of table 1517_c_b1kl_1_l_2_n512_batch_sample_sample is 0.15800712358271993\n",
      "The mean mse value for all columns of table CGANEPOCH2 is 0.04191635334582556\n",
      "The mean r2 value for all columns  of table CGANEPOCH2 is -80.20228935918523 \n",
      "The correlation for mse of all columns of table CGANEPOCH2 is 0.9252768294354115\n",
      "The correlation for r2 of all columns of table CGANEPOCH2 is -0.2859626694437572\n",
      "The mean mse value for all columns of table 1517_c_b1kl_1_l_2_n512_oversample_02_sample is 0.0016984572480969846\n",
      "The mean r2 value for all columns  of table 1517_c_b1kl_1_l_2_n512_oversample_02_sample is -3.573284613390579 \n",
      "The correlation for mse of all columns of table 1517_c_b1kl_1_l_2_n512_oversample_02_sample is 0.4865972871825596\n",
      "The correlation for r2 of all columns of table 1517_c_b1kl_1_l_2_n512_oversample_02_sample is -0.17249129138902106\n",
      "The mean mse value for all columns of table 1517_c_b1kl_1_l_2_n512_oversample_01_sample is 0.0008025894671183865\n",
      "The mean r2 value for all columns  of table 1517_c_b1kl_1_l_2_n512_oversample_01_sample is -2.2824583151468163 \n",
      "The correlation for mse of all columns of table 1517_c_b1kl_1_l_2_n512_oversample_01_sample is 0.895279582574269\n",
      "The correlation for r2 of all columns of table 1517_c_b1kl_1_l_2_n512_oversample_01_sample is -0.12476938586605636\n",
      "The mean mse value for all columns of table 1517_c_b1kl_1_l_2_n512_oversample_005_sample is 0.004429729631072053\n",
      "The mean r2 value for all columns  of table 1517_c_b1kl_1_l_2_n512_oversample_005_sample is -11.325862664381876 \n",
      "The correlation for mse of all columns of table 1517_c_b1kl_1_l_2_n512_oversample_005_sample is 0.8789036551865874\n",
      "The correlation for r2 of all columns of table 1517_c_b1kl_1_l_2_n512_oversample_005_sample is -0.10832400295184436\n",
      "The mean mse value for all columns of table 1517_c_b1kl_1_l_2_n512_oversample_001_sample is 0.00021935271294141947\n",
      "The mean r2 value for all columns  of table 1517_c_b1kl_1_l_2_n512_oversample_001_sample is -4.874767230877328 \n",
      "The correlation for mse of all columns of table 1517_c_b1kl_1_l_2_n512_oversample_001_sample is 0.5839649326473241\n",
      "The correlation for r2 of all columns of table 1517_c_b1kl_1_l_2_n512_oversample_001_sample is -0.2065332985544072\n"
     ]
    }
   ],
   "source": [
    "test_eval_dict = {}\n",
    "\n",
    "for key in sorted_test_data_dict.keys():\n",
    "    test_eval_dict[key] = {}\n",
    "    mse_list = []\n",
    "    r2_list = []\n",
    "\n",
    "    for i in range(30):\n",
    "        X = np.delete(sorted_test_data_dict[key], i, axis=1)\n",
    "        y = sorted_test_data_dict[key][:, i]\n",
    "        model = regression_dict_test[i][\"model\"]\n",
    "        mse, r2 = evaluate_model_performance_regression(X, y, model)\n",
    "        mse_list.append(mse)\n",
    "        r2_list.append(r2)\n",
    "    mse_mean = sum(mse_list) / len(mse_list)\n",
    "    r2_mean = sum(r2_list) / len(r2_list)\n",
    "\n",
    "    test_eval_dict[key][\"mse\"] = mse_mean\n",
    "    test_eval_dict[key][\"r2\"] = r2_mean\n",
    "    test_eval_dict[key][\"mse_list\"] = mse_list\n",
    "    test_eval_dict[key][\"r2_list\"] = r2_list\n",
    "    correlation_mse = np.corrcoef(\n",
    "        test_eval_dict[\"sorted_test_data_mm\"][\"mse_list\"], test_eval_dict[key][\"mse_list\"]\n",
    "    )[0, 1]\n",
    "    test_eval_dict[key][\"correlation_mse\"] = correlation_mse\n",
    "    correlation_r2 = np.corrcoef(\n",
    "        test_eval_dict[\"sorted_test_data_mm\"][\"r2_list\"], test_eval_dict[key][\"r2_list\"]\n",
    "    )[0, 1]\n",
    "    test_eval_dict[key][\"correlation_r2\"] = correlation_r2\n",
    "\n",
    "    print(f\"The mean mse value for all columns of table {key} is {mse_mean}\")\n",
    "    print(f\"The mean r2 value for all columns  of table {key} is {r2_mean} \")\n",
    "    print(f\"The correlation for mse of all columns of table {key} is {correlation_mse}\")\n",
    "    print(f\"The correlation for r2 of all columns of table {key} is {correlation_r2}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "var_auto",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
