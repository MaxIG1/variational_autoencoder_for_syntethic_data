{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kaggle\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kaggle.api.dataset_download_files(\"mlg-ulb/creditcardfraud\", path=\"../data/raw\", unzip=True)\n",
    "df_full = pd.read_csv(\"../data/raw/creditcard.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Z-Noramlisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_normalised = df_full\n",
    "for column in df_normalised.columns[:-1]:\n",
    "    std = np.std(df_normalised[column])\n",
    "    mean = np.mean(df_normalised[column])\n",
    "    df_normalised[column] = df_normalised[column] - mean\n",
    "    df_normalised[column] = df_normalised[column] / std\n",
    "\n",
    "df_normalised.to_csv(\"../data/interim/creditcard_z_normalised.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Min Max Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaler.fit(df_full)\n",
    "scaled_data = scaler.transform(df_full)\n",
    "scaled_df = pd.DataFrame(scaled_data, columns=df_full.columns)\n",
    "scaled_df.to_csv(\"../data/interim/creditcard_min_max.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outlier Elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scaled = pd.read_csv(\"../data/interim/creditcard_min_max.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers(df, end_column=30):\n",
    "    # Select columns up to end_column\n",
    "    df_selected = df.iloc[:, :end_column]\n",
    "\n",
    "    # Calculate mean and standard deviation for each selected column\n",
    "    mean = df_selected.mean()\n",
    "    std = df_selected.std()\n",
    "\n",
    "    # Define threshold for outliers\n",
    "    threshold = 3 * std\n",
    "\n",
    "    # Create a boolean mask for outliers\n",
    "    outliers = np.abs(df_selected - mean) > threshold\n",
    "\n",
    "    # Return DataFrame without outliers\n",
    "    return df[~outliers.any(axis=1)]\n",
    "\n",
    "\n",
    "# Remove outliers up to column 30\n",
    "cleaned_df = remove_outliers(df_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cleaned_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mcleaned_df\u001b[49m\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../data/interim/outliers_removed.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cleaned_df' is not defined"
     ]
    }
   ],
   "source": [
    "cleaned_df.to_csv(\"../data/interim/outliers_removed.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First X Percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the DataFrame from the CSV file\n",
    "df_min_max = pd.read_csv(\"../data/interim/creditcard_min_max.csv\")\n",
    "df_min_max_array = df_min_max.values\n",
    "total_length = len(df_min_max_array)\n",
    "\n",
    "# Calculate 20% of the total length\n",
    "twenty_percent_length = int(0.1 * total_length)\n",
    "\n",
    "# Slice the first 20 percent of the values in df_min_max_array\n",
    "df_min_max_array_cut = df_min_max_array[:twenty_percent_length]\n",
    "\n",
    "# Create a DataFrame from the sliced array and specify columns\n",
    "df_min_max_cut = pd.DataFrame(df_min_max_array_cut, columns=df_min_max.columns)\n",
    "\n",
    "# Save the sliced data to a new CSV file\n",
    "df_min_max_cut.to_csv(\"../data/interim/cut_data.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting the Data in Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_credit = pd.read_csv(\"../data/interim/creditcard_min_max.csv\")\n",
    "credit_array = df_credit.values\n",
    "\n",
    "\n",
    "# Specify the test_size and validation_size according to your needs\n",
    "test_size = 0.2  # 80% training, 20% test\n",
    "validation_size = 0.1  # 80% training, 10% validation\n",
    "\n",
    "# Split into training and temporary data\n",
    "train_data, temp_data = train_test_split(\n",
    "    df_credit, test_size=test_size + validation_size, random_state=42\n",
    ")\n",
    "\n",
    "# Split the temporary data into test and validation\n",
    "test_data, validation_data = train_test_split(\n",
    "    temp_data,\n",
    "    test_size=validation_size / (test_size + validation_size),\n",
    "    random_state=69)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the unsorted\n",
    "train_data.to_csv(\"../data/processed/shuffled_train_data_mm.csv\", index=False)\n",
    "test_data.to_csv(\"../data/processed/shuffled_test_data_mm.csv\", index=False)\n",
    "validation_data.to_csv(\"../data/processed/shuffled_val_data_mm.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_train_data = train_data.sort_values(by=\"Time\")\n",
    "sorted_test_data = test_data.sort_values(by=\"Time\")\n",
    "sorted_val_data = validation_data.sort_values(by=\"Time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_data 0.0016151118289385905\n",
      "train_data 0.0017856784574948336\n",
      "val_data 0.001544889575506478\n"
     ]
    }
   ],
   "source": [
    "print('test_data', sum(test_data.Class) / len(test_data))\n",
    "print(\"train_data\", sum(train_data.Class) / len(train_data))\n",
    "print(\"val_data\", sum(validation_data.Class) / len(validation_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_train_data.to_csv(\"../data/processed/sorted_train_data_mm.csv\", index=False)\n",
    "sorted_test_data.to_csv(\"../data/processed/sorted_test_data_mm.csv\", index=False)\n",
    "sorted_val_data.to_csv(\"../data/processed/sorted_val_data_mm.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Sampling out of the whole dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full = pd.read_csv(\"../data/interim/creditcard_min_max.csv\")\n",
    "\n",
    "total_rows = len(df_full)\n",
    "subset_size = int(0.1 * total_rows)\n",
    "\n",
    "# Generate random indices for the first subset and sample\n",
    "df_train = df_full.sample(n=subset_size, replace=False)\n",
    "df_train_incides = df_full.sample(n=subset_size, replace=False).index\n",
    "\n",
    "# drop the indices to be sure no overlapping\n",
    "df_dropped = df_full.drop(df_train_incides)\n",
    "df_test = df_full.sample(n=subset_size, replace=False)\n",
    "\n",
    "len(df_train) == len(df_test)\n",
    "\n",
    "# save the random sample df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv(\"../data/interim/privacy_testing/train_random_sample.csv\", index=False)\n",
    "df_test.to_csv(\"../data/interim/privacy_testing/test_random_sample.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Oversampled Minority Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"../data/processed/sorted_train_data_mm.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.drop(\n",
    "    columns=[\"Class\"]\n",
    ") \n",
    "y_train = df_train[\"Class\"]\n",
    "\n",
    "# Random oversampling with a sampling strategy of 10 percent\n",
    "ros = RandomOverSampler(sampling_strategy=0.1, random_state=42)\n",
    "X_train_resampled, y_train_resampled = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "df_resampled = pd.DataFrame(X_train_resampled, columns=X_train.columns)\n",
    "df_resampled[\"Class\"] = y_train_resampled\n",
    "df_resampled.sort_values(\"Time\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resampled.to_csv(\"../data/processed/train_oversampled_01.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "ros = RandomOverSampler(sampling_strategy=0.2, random_state=42)\n",
    "X_train_resampled, y_train_resampled = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "# Random oversampling with a sampling strategy of 20 percent\n",
    "df_resampled = pd.DataFrame(X_train_resampled, columns=X_train.columns)\n",
    "df_resampled[\"Class\"] = y_train_resampled\n",
    "df_resampled.sort_values(\"Time\", inplace=True)\n",
    "\n",
    "df_resampled.to_csv(\"../data/processed/train_oversampled_02.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.drop(columns=[\"Class\"])\n",
    "y_train = df_train[\"Class\"]\n",
    "\n",
    "# Random oversampling with a sampling strategy of 5 percent\n",
    "ros = RandomOverSampler(sampling_strategy=0.05, random_state=42)\n",
    "X_train_resampled, y_train_resampled = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "df_resampled = pd.DataFrame(X_train_resampled, columns=X_train.columns)\n",
    "df_resampled[\"Class\"] = y_train_resampled\n",
    "df_resampled.sort_values(\"Time\", inplace=True)\n",
    "df_resampled.to_csv(\"../data/processed/train_oversampled_005.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.drop(columns=[\"Class\"])\n",
    "y_train = df_train[\"Class\"]\n",
    "\n",
    "# Random oversampling with a sampling strategy of 1 percent\n",
    "ros = RandomOverSampler(sampling_strategy=0.01, random_state=42)\n",
    "X_train_resampled, y_train_resampled = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "df_resampled = pd.DataFrame(X_train_resampled, columns=X_train.columns)\n",
    "df_resampled[\"Class\"] = y_train_resampled\n",
    "df_resampled.sort_values(\"Time\", inplace=True)\n",
    "df_resampled.to_csv(\"../data/processed/train_oversampled_001.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"../data/interim/cut_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.drop(columns=[\"Class\"])\n",
    "y_train = df_train[\"Class\"]\n",
    "\n",
    "# Random oversampling with a sampling strategy of 5 percent\n",
    "ros = RandomOverSampler(sampling_strategy=0.05, random_state=42)\n",
    "X_train_resampled, y_train_resampled = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "df_resampled = pd.DataFrame(X_train_resampled, columns=X_train.columns)\n",
    "df_resampled[\"Class\"] = y_train_resampled\n",
    "df_resampled.sort_values(\"Time\", inplace=True)\n",
    "df_resampled.to_csv(\"../data/interim/train_cut_oversampled_005.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "var_auto",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
